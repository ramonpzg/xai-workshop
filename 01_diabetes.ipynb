{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI in Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github.com/ramonpzg/xai-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Q&As\n",
    "3. Dependencies\n",
    "4. Data\n",
    "5. Model Training\n",
    "6. Model Evaluation\n",
    "7. Model Interpretation\n",
    "8. Summary\n",
    "9. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetes is a chronic, metabolic disease characterized by elevated levels \n",
    "of blood glucose (or blood sugar), which leads over time to serious damage to the \n",
    "heart, blood vessels, eyes, kidneys and nerves. There are different kinds of diabetes \n",
    "diseases and, sadly, a lot of people can be living with at least one of them without knowing it.\n",
    "\n",
    "The issue is so pronounced that the International Diabetes Federation said\n",
    "\n",
    "> The IDF Diabetes Atlas (2021) reports that 10.5% of the adult population (20-79 years) \n",
    "has diabetes, with almost half unaware that they are living with the condition. By 2045, \n",
    "IDF projections show that 1 in 8 adults, approximately 783 million, will be living with \n",
    "diabetes, an increase of 46%.\n",
    "\n",
    "That said, imagine we could turn to machine learning to help us detect who might be diabetic \n",
    "and not know it, or who could be closer to becoming one? Wouldn't that be not only ideal, but also \n",
    "desirable by everyone? I think it is but it is important to keep in mind that a simple message \n",
    "with \"Hey, just wanted to tell that you have diabetes!\" won't suffice. Context and a good explanation \n",
    "will go a long way and can also provide the patient with useful information for his/her/their loved \n",
    "ones, should some of the variables causing the illness were to be highly hereditary.\n",
    "\n",
    "With this overview out of the way, let's examine some questions our patients may want to know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Q&As"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When talking to a professional that used an algorithm to tell me if I am sick or not, I would \n",
    "most certainly ask the following (at the very least).\n",
    "\n",
    "1. Why did I get flagged as diabetic or potentially becoming one in the near future?\n",
    "2. What led to this conclusion?\n",
    "3. What should I do next?\n",
    "\n",
    "Some potential answers \"I\" would like to hear if my doctor was telling me that I have diabetes \n",
    "would be:\n",
    "1. Your level of glucose was extremely high and this, and other variables, contributed towards \n",
    "flagging you as having diabetes. If you had a fasting blood glucose test, a level between 70 \n",
    "and 100 mg/dL (3.9 and 5.6 mmol/L) is considered normal. Yours was at 130.\n",
    "2. The combination of high glucose and blood preassure, your age, and your skin thickness, increased \n",
    "the likelihood of you having diabetes when compare to other patients similar to you.\n",
    "3. We would need to first have you take a few tests to figure out if you this is a false positive or \n",
    "if you indeed have diabetes and, if so, of which kind (type I or type II). In addition, we would \n",
    "be giving you guidelines and steps to take to bring your glucose to normal levels, and we will also \n",
    "ask you to come again soon for more regular check ups.\n",
    "\n",
    "More or less that would make me feel a bit more positive about the situation. Nonetheless, there are \n",
    "many factors leading to diabetes that would take too long to go over so let's get started with our \n",
    "example. ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the packages we will be using in this notebook.\n",
    "\n",
    "- `scikit-learn`\n",
    "- `pandas`\n",
    "- `joblib`\n",
    "- `matplotlib`\n",
    "- `alibi`\n",
    "- `statsmodels`\n",
    "- `mlserver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn pandas joblib matplotlib alibi numpy rich mlserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using can be downloaded from kaggle \n",
    "[here](https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset). It is \n",
    "an abreviated version from the **National Institute of Diabetes and Digestive and Kidney \n",
    "Diseases**. This dataset contains a very specific information such as all femaile, over 21, \n",
    "and from a particular region of India, but it can serve as a starting point for a much \n",
    "larger project with many more variables.\n",
    "\n",
    "Why it matters? Machine learning is great at finding patterns in the data, and we should use \n",
    "this tools, with the appropriate measures in place, as best we can to enhance human life. A lot \n",
    "of illnesses become fatal ones due to late detection, therefore, if there is a way to help people \n",
    "of all backgrounds while keeping their information and rights safe and intact, we should be doing \n",
    "what we can to push the needle forward.\n",
    "\n",
    "Description or dictionary of variables.\n",
    "- `Pregnancies` - number of pregnancies.\n",
    "- `Glucose` - glucose level.\n",
    "- `BloodPressure` - blood pressure.\n",
    "- `SkinThickness`\n",
    "- `Insulin` - level of insulin in the blood.\n",
    "- `BMI` - body ass index.\n",
    "- `DiabetesPedigreeFunction`\n",
    "- `Age`\n",
    "- `Outcome` - target variable.\n",
    "\n",
    "Let's get started evaluating loading and evaluating our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from rich import print\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diabetes/diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Outcome']\n",
    "X = df.drop(['Outcome'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we will use a logistic regression because of its high degree of interpretability \n",
    "and ease of use via the packages described two sections back.\n",
    "\n",
    "If you have never used a logistic regression before, you can think of it as a classification \n",
    "algorithm used to predict a binary outcome (e.g. 1 or 0, white or black, cat or not cat, etc).\n",
    "\n",
    "For a quick example, suppose you are an instructor that wants to predict if a student will \n",
    "pass an exam (a binary, yes/no outcome) based on hours studied, previous grades, and, \n",
    "potentially, other variables. Your process might look as follows.\n",
    "\n",
    "1. Convert the output to a probability value between 0-1. This will represent the chance of passing.\n",
    "\n",
    "2. Use a linear model to combine the input features and calculate a 'score'. \n",
    "    \n",
    "    $score = Intercept + HoursStudied * \\beta_1 + PreviousGrades * \\beta_2$\n",
    "\n",
    "3. Step 3: Convert this score to a probability using the logistic function:\n",
    "    \n",
    "    $probability = \\frac{1}{(1 + e^{(-score)})}$\n",
    "    This squashes the score to between 0 and 1.\n",
    "\n",
    "4. If probability > 0.5, predict the student will pass. Otherwise predict they will fail. The \n",
    "probabilities provide a measure of confidence in the binary predictions.\n",
    "\n",
    "While the above example is a shorter version of the process, my hope is that it gives you an intuition \n",
    "for how the method works in practice. \n",
    "\n",
    "Now, let's train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to experiment with the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls = LogisticRegression(random_state=0, max_iter=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have the path below, you can create with the following command in the termianl.\n",
    "\n",
    "```sh\n",
    "mkdir -p models/diabetes/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/diabetes/lr_cls_diabetes.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_cls, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check before we move on to thoroughly evaluating our model. For this, we will \n",
    "pick a random sample from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test.sample(1)\n",
    "y = y_test[x.index[0]]\n",
    "print(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Confusion matrix for Logistic Regression'\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    lr_cls, X_test, y_test, \n",
    "    display_labels=['Not Diabetic', 'Diabetic'],\n",
    "    cmap=plt.cm.Blues, normalize=None\n",
    ")\n",
    "disp.ax_.set_title(title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method we will explore is called [Kernel SHAP](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html#:~:text=Kernel%20SHAP%20is%20a%20method,modelfunction%20or%20iml.Model).\n",
    "\n",
    "> It is a model interpretation method that explains individual predictions by determining \n",
    "the contribution of each feature. It uses concepts from game theory and local surrogate models \n",
    "to quantify feature importance.\n",
    "\n",
    "Here's an analogy to understand Kernel SHAP:\n",
    "\n",
    "Imagine a fruit smoothie prediction model. The ingredients are bananas, strawberries, yogurt, \n",
    "and ice. The model predicts how sweet the smoothie will taste.\n",
    "\n",
    "To explain an individual prediction, Kernel SHAP is like asking:\n",
    "\n",
    "\"How much did each ingredient contribute to the overall sweetness?\" \n",
    "\n",
    "It determines the SHAP value, or impact, of each feature by comparing smoothies with and without \n",
    "that ingredient. Bananas may get a high positive SHAP value because they make smoothies much \n",
    "sweeter. Ice may have a negative SHAP value since it dilutes the sweetness. By summing the SHAP \n",
    "values for all features, Kernel SHAP explains the total predicted sweetness. It reveals why \n",
    "the model predicted that particular level of sweetness given those ingredients.\n",
    "\n",
    "Like this, Kernel SHAP attributes the prediction of any complex model to each input feature. The \n",
    "analogy helps convey how it quantifies each feature's contribution, like ingredients in a recipe. This \n",
    "makes model behavior more interpretable.\n",
    "\n",
    "You can learn more about Kernel Shap [here](https://docs.seldon.io/projects/alibi/en/stable/examples/kernel_shap_wine_intro.html).\n",
    "\n",
    "Let's get started implementing `KernelShap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import KernelShap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = KernelShap(lr_cls.predict_proba, task='classification')\n",
    "explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explainers in Alibi work in the same fashion as estimators in sklearn, that is, they follow the \n",
    "`.fit()` and `.predict()` way of doing things so if you are familiar with sklearn, this step will \n",
    "feel familiar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we finish creating an explainer, the object we get back gives us a lot of useful information like the one above.\n",
    "\n",
    "Note that, running an explainer in a large batch of data can be quite compute intensive (depending on the \n",
    "explainer of course), so it is good practice to save your models once your code finishes creating them. Let's \n",
    "save ours, load it and test it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_path = 'models/diabetes/lr_cls_explainer.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(explainer, explainer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = joblib.load(explainer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test.sample(1)\n",
    "y = y_test[x.index].iloc[0]\n",
    "print(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.to_list()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed in the metadata returned to us once we trained our model, `KernelShap` is both \n",
    "local and global, which means that it can be applied to one or many samples at a time. Let's try it on our \n",
    "random sample from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = explainer.explain(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're interested in is the `shap_values` returned by our explainer. Let's see what these look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shap_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(feat_imp, feat_names, class_idx):\n",
    "    df = pd.DataFrame(data=feat_imp, columns=feat_names).sort_values(by=0, axis='columns')\n",
    "    feat_imp, feat_names = df.values[0], df.columns\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    y_pos = np.arange(len(feat_imp))\n",
    "    ax.barh(y_pos, feat_imp)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feat_names, fontsize=15)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(f'Feature effects for class {class_idx}', fontsize=15)\n",
    "    return ax, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(result.shap_values[1], features, 'No Diabetes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = explainer.explain(X_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(result.shap_values[0], X_train[:100], features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive SHAP value means the feature pushed the output higher. Negative means it pushed the output lower.\n",
    "\n",
    "It is important to note that, if we train the explainer on a large amount of data (with some compute expenses), the \n",
    "explainer would have learned enough about the model globally to locally explain the interactions for new cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the explainer method we choose, Kernel Shap, to explain our model is considered a black-box method, \n",
    "because we choose a logistic regresion as our class, we can also interrogate each of the coefficients of our \n",
    "model and interpret further the result we got.\n",
    "\n",
    "To do this, we will make use of `statsmodels` to fit a model again because it has a very nice summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "log_result = log_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above we can examine not only the coefficients of each parameter, but also the standard deviation and \n",
    "AIC and BIC values of our model.\n",
    "\n",
    "Because the coefficients are the logarithms of the odds (i.e. the probability of a positive case over \n",
    "the probability of a negative case), we can convert them back into exponentials to get a better sense of \n",
    "what each value means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(log_result.params).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the odds mean for a diabetic patient? It means that the odds of having Diabetes increase by a factor of 2.95 for each additional unit of DiabetesPedigreeFunction, or by 1.14 for every new pregnancy, provided every other feature stays unchanged.\n",
    "\n",
    "We need more context for this, and that can be achieved with the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = log_result.params.drop(labels=['const'])\n",
    "stdv = np.std(X_train, 0)\n",
    "abs(coefs * stdv).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding table can be interpreted as an approximation of risk factors from high to low \n",
    "according to the model. It is also a model-specific feature importance method, and a global one \n",
    "at that (as it was gather from a group of samples). It tells us how far away from the mean each of \n",
    "these values are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explainable AI (XAI) is a set of techniques and methods that enable machine learning models \n",
    "to provide clear, understandable, and human-interpretable explanations for their predictions, \n",
    "helping users develop trust and make informed decisions based on machine learning outputs.\n",
    "\n",
    "2. Kernel SHAP is a specific XAI method that attributes the impact of each input feature on a \n",
    "model's prediction by using a game theoretic framework, providing insights into how features \n",
    "influence the model's outcomes.\n",
    "\n",
    "3. Logistic regression is a statistical model commonly used in machine learning for binary \n",
    "classification tasks. It estimates the probability of a binary outcome by fitting a linear \n",
    "function to input features and applying a logistic (sigmoid) transformation.\n",
    "\n",
    "4. XAI can be used to enhance transparency, accountability, and trust in AI systems, \n",
    "especially in critical domains like healthcare, where decisions based on AI can have significant \n",
    "real-world consequences. XAI helps uncover the black-box nature of complex models and makes \n",
    "their reasoning accessible to human experts.\n",
    "\n",
    "5. Machine Learning can assist in diagnosing diseases in deceased individuals by analyzing medical data, \n",
    "potentially improving the accuracy and efficiency of diagnoses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Serving our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To serve models and explainers together, you can run a server with both models using `mlserver`. \n",
    "To do so, run the following command.\n",
    "\n",
    "```sh\n",
    "python servers/diabetes/cls_diabetes_service.py\n",
    "```\n",
    "\n",
    "You can test that your server is working with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlserver.codecs import NumpyCodec\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_request = {\n",
    "    'inputs': [\n",
    "        NumpyCodec.encode_input(name='payload', payload=x.values).dict()\n",
    "    ]\n",
    "}\n",
    "print(inf_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the name from **classifier** to **explainer** and back to change the endpoint you \n",
    "are hitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'diabetes_classifier'\n",
    "endpoint = f\"http://0.0.0.0:8080/v2/models/{model}/infer\"\n",
    "r = requests.post(endpoint, json=inf_request)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Explainer on Hospital Readmission Data\n",
    "\n",
    "- Load the hospital [readmission dataset](https://www.kaggle.com/datasets/dubradave/hospital-readmissions). No \n",
    "need to use all features. 10 features including age, medications, vitals, etc., would suffice.\n",
    "- Train a logistic regression model to predict readmission.\n",
    "- Create a Kernel Shap explainer using Alibi, or use another method from a different Alibi like AnchorTabular \n",
    "or CounterFactual, or from another library.\n",
    "- Write a short narrative describing the result. \n",
    "- Compare the explanations if you choose more than one model - which features do they highlight? How do they differ? \n",
    "and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
