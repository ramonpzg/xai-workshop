{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated gradients for text classification on the IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Data\n",
    "3. Model Training\n",
    "4. Model Evaluation\n",
    "5. Summary\n",
    "6. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we apply the integrated gradients method to a sentiment analysis model \n",
    "trained on the IMDB dataset. In text classification models, integrated gradients define \n",
    "an attribution value for each word in the input sentence. The attributions are calculated \n",
    "considering the integral of the model gradients with respect to the word embedding layer \n",
    "along a straight path from a baseline instance $x^\\prime$ to the input instance $x$. A \n",
    "description of the method can be found \n",
    "[here](https://docs.seldon.io/projects/alibi/en/stable/methods/IntegratedGradients.html). Integrated \n",
    "gradients was originally proposed in Sundararajan et al., \n",
    "[\"Axiomatic Attribution for Deep Networks\"](https://arxiv.org/abs/1703.01365)\n",
    "\n",
    "The IMDB data set contains 50K movie reviews labelled as positive or negative. We train a \n",
    "convolutional neural network classifier with a single 1-d convolutional layer followed by a \n",
    "fully connected layer. The reviews in the dataset are truncated at 100 words and each word \n",
    "is represented by 50-dimesional word embedding vector. We calculate attributions for the \n",
    "elements of the embedding layer.\n",
    "\n",
    "Note: To enable support for IntegratedGradients, you may need to run\n",
    "    \n",
    "```bash\n",
    "pip install alibi[tensorflow]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from alibi.explainers import IntegratedGradients\n",
    "import matplotlib.pyplot as plt\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the IMDB dataset has a lot of reviews with different amounts of words so, for our \n",
    "purposes, we'll limit the amount of tokens we get back for our examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(max_features):\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "train_labels.shape, train_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_categorical??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.pad_sequences??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()}\n",
    "\n",
    "i = 0\n",
    "for k, v, in reverse_index.items():\n",
    "    print(f\"Key --> {k} represents Value --> {v}\")\n",
    "    print(\"-\"*10)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample review from the test set. Note that unknown words are replaced with 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(x, reverse_index):\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decode_sentence(x_test[1], reverse_index)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model includes one convolutional layer and reaches a test accuracy of 0.85. If \n",
    "`save_model = True`, a local folder `../model_imdb` will be created and the trained \n",
    "model will be saved in that folder. If the model was previously saved, it can be \n",
    "loaded by setting `load_model = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './models/model_imdb/'  # change to directory where model is downloaded\n",
    "if load_model:\n",
    "    model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))\n",
    "else:\n",
    "    print('Build model...')\n",
    "    \n",
    "    inputs = Input(shape=(maxlen,), dtype=tf.int32)\n",
    "    embedded_sequences = Embedding(max_features, embedding_dims)(inputs)\n",
    "\n",
    "    out = Conv1D(\n",
    "        filters, kernel_size, padding='valid', activation='relu', strides=1\n",
    "    )(embedded_sequences)\n",
    "\n",
    "    out     = Dropout(0.4)(out)\n",
    "    out     = GlobalMaxPooling1D()(out)\n",
    "    out     = Dense(hidden_dims, activation='relu')(out)\n",
    "    out     = Dropout(0.4)(out)\n",
    "    \n",
    "    outputs = Dense(2, activation='softmax')(out)\n",
    "        \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(\n",
    "        x_train, y_train, batch_size=256, epochs=3, validation_data=(x_test, y_test)\n",
    "    )\n",
    "    \n",
    "    if save_model:  \n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        model.save(os.path.join(filepath, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integrated gradients attributions are calculated with respect to the embedding layer for \n",
    "10 samples from the test set. Since the model uses a word to vector embedding with vector \n",
    "dimensionality of 50 and sequence length of 100 words, the dimensionality of the attributions \n",
    "is (10, 100, 50). In order to obtain a single attribution value for each word, we sum all \n",
    "the attribution values for the 50 elements of each word's vector representation.\n",
    " \n",
    "The default baseline is used in this example which is internally defined as a sequence of \n",
    "zeros. In this case, this corresponds to a sequence of padding characters (**NB:** in general \n",
    "the numerical value corresponding to a \"non-informative\" baseline such as the PAD token will \n",
    "depend on the tokenizer used, make sure that the numerical value of the baseline used corresponds \n",
    "to your desired token value to avoid surprises). The path integral is defined as a straight \n",
    "line from the baseline to the input image. The path is approximated by choosing 50 discrete \n",
    "steps according to the Gauss-Legendre method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layers[1]\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 100\n",
    "nb_samples = 10\n",
    "\n",
    "ig  = IntegratedGradients(\n",
    "    model, layer=layer, n_steps=n_steps, method=method, internal_batch_size=internal_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sample = x_test[:nb_samples]\n",
    "\n",
    "predictions = model(x_test_sample).numpy().argmax(axis=1)\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = ig.explain(\n",
    "    x_test_sample, baselines=None, target=predictions, attribute_to_layer_inputs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata from the explanation object\n",
    "explanation.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data fields from the explanation object\n",
    "explanation.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)\n",
    "attrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)\n",
    "attrs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to visualize the attributions of our model. We can do so for the text instance by \n",
    "mapping the values of the attributions onto a matplotlib colormap. Below we define some \n",
    "utility functions for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm       = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap       = mpl.cm.get_cmap(cmap)\n",
    "    \n",
    "    return list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can visualize the attribution values (highlighted in the text) having the highest \n",
    "positive attributions. Words with high positive attribution are highlighted in shades of \n",
    "green and words with negative attribution in shades of pink. Stronger shading corresponds \n",
    "to higher attribution values. Positive attributions can be interpreted as increase in \n",
    "probability of the predicted class (\"Positive sentiment\") while negative attributions \n",
    "correspond to decrease in probability of the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "x_i       = x_test_sample[i]\n",
    "attrs_i   = attrs[i]\n",
    "pred      = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words  = decode_sentence(x_i, reverse_index).split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = colorize(attrs_i)\n",
    "colors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Integrated gradients for NLP help us evaluate the contribution of each token with respect to \n",
    "the predicted variable.\n",
    "\n",
    "- Integrated gradients is a model agnostic explainability method and can be used with different \n",
    "models and not only different data modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the reuters dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.____ import ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "(___, ___), (___, ___) = ____.load_data(num_words=____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the shape of your data, both training and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), [1, 2, 2, 8, 43, 10, 447, 5, 25, 207])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,),\n",
       " array([ 3,  4,  3,  4,  4,  4,  4,  3,  3, 16,  3,  3,  4,  4, 19,  8, 16,\n",
       "         3,  3, 21]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "____ = ____.____()\n",
    "____ = y_train.____()\n",
    "train_labels.shape, train_labels[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the classes into categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "____, ____ = to_categorical(____), to_categorical(____)\n",
    "____[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(____, maxlen=____)\n",
    "x_test  = sequence.pad_sequences(____, maxlen=____)\n",
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of both again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8982, 100)\n",
      "x_test shape: (2246, 100)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the words index and print a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key --> 10996 represents Value --> mdbl\n",
      "----------\n",
      "Key --> 16260 represents Value --> fawc\n",
      "----------\n",
      "Key --> 12089 represents Value --> degussa\n",
      "----------\n",
      "Key --> 8803 represents Value --> woods\n",
      "----------\n",
      "Key --> 13796 represents Value --> hanging\n",
      "----------\n",
      "Key --> 20672 represents Value --> localized\n",
      "----------\n",
      "Key --> 20673 represents Value --> sation\n",
      "----------\n",
      "Key --> 20675 represents Value --> chanthaburi\n",
      "----------\n",
      "Key --> 10997 represents Value --> refunding\n",
      "----------\n",
      "Key --> 8804 represents Value --> hermann\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "index = reuters.____()\n",
    "reverse_index = {value: key for (key, value) in index.items()}\n",
    "\n",
    "i = 0\n",
    "for ____, ____ in reverse_index.____():\n",
    "    ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode one sentence to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without any justification manila was UNK watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\n"
     ]
    }
   ],
   "source": [
    "print(decode_sentence(____[1], ____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - ETA: 0s - loss: 2.7667 - accuracy: 0.3575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 08:10:53.730043: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-09-17 08:10:53.730068: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 27ms/step - loss: 2.7667 - accuracy: 0.3575 - val_loss: 2.3074 - val_accuracy: 0.3642\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 2.0163 - accuracy: 0.4644 - val_loss: 1.9641 - val_accuracy: 0.5178\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 1.7944 - accuracy: 0.5296 - val_loss: 1.8191 - val_accuracy: 0.5548\n"
     ]
    }
   ],
   "source": [
    "filepath = './models/model_reuters/'  # change to directory where model is downloaded\n",
    "\n",
    "inputs = Input(shape=(maxlen,), dtype=tf.int32)\n",
    "embedded_sequences = Embedding(max_features, embedding_dims)(inputs)\n",
    "\n",
    "out = Conv1D(\n",
    "    filters, kernel_size, padding='valid', activation='relu', strides=1\n",
    ")(embedded_sequences)\n",
    "\n",
    "out     = Dropout(0.4)(out)\n",
    "out     = GlobalMaxPooling1D()(out)\n",
    "out     = Dense(hidden_dims, activation='relu')(out)\n",
    "out     = Dropout(0.4)(out)\n",
    "\n",
    "outputs = Dense(46, activation='softmax')(out)\n",
    "    \n",
    "model = Model(inputs=inputs, outputs=_____)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(\n",
    "    _____, _____, batch_size=256, epochs=3, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it with a unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "model.save(os.path.join(filepath, '_____.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f8bcd330c70>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.layers[1]\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 100\n",
    "\n",
    "\n",
    "ig  = IntegratedGradients(\n",
    "    _____, layer=_____, n_steps=_____, method=_____, internal_batch_size=_____\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a few samples and predict their class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 19,  3,  3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = _____\n",
    "_____ = x_test[:nb_samples]\n",
    "\n",
    "predictions = model(_____).numpy().argmax(axis=1)\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the samples above. No baseline needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = ig.explain(\n",
    "    _____, baselines=None, target=_____, attribute_to_layer_inputs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'IntegratedGradients',\n",
       " 'type': ['whitebox'],\n",
       " 'explanations': ['local'],\n",
       " 'params': {'target_fn': None,\n",
       "  'method': 'gausslegendre',\n",
       "  'n_steps': 50,\n",
       "  'internal_batch_size': 100,\n",
       "  'layer': 1},\n",
       " 'version': '0.9.4'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attributions', 'X', 'forward_kwargs', 'baselines', 'predictions', 'deltas', 'target'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data fields from the explanation object\n",
    "explanation.data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the attribution values from your explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.,  0., -0., ...,  0.,  0., -0.],\n",
       "       [-0., -0., -0., ..., -0.,  0., -0.],\n",
       "       [ 0.,  0., -0., ..., -0., -0., -0.],\n",
       "       ...,\n",
       "       [-0.,  0.,  0., ..., -0., -0., -0.],\n",
       "       [-0.,  0., -0., ..., -0., -0., -0.],\n",
       "       [-0.,  0., -0., ...,  0., -0., -0.]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = _____._____[0]\n",
    "print('Attributions shape:', attrs.shape)\n",
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the attributions of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "x_i       = x_test_sample[i]\n",
    "attrs_i   = attrs[i]\n",
    "pred      = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'UNK', 'in', 'august', '1986', 'and', 'UNK', 'in', 'december', 'helped']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words  = decode_sentence(x_i, reverse_index).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = colorize(attrs_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate different samples as well and see if the words highlighted make sense as the \n",
    "contributors to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#f7f7f6>of </mark><mark style=background-color:#f7f7f6>UNK </mark><mark style=background-color:#f7f7f6>in </mark><mark style=background-color:#f7f7f6>august </mark><mark style=background-color:#f7f7f6>1986 </mark><mark style=background-color:#f7f7f6>and </mark><mark style=background-color:#f7f7f6>UNK </mark><mark style=background-color:#f7f7f6>in </mark><mark style=background-color:#f7f7f6>december </mark><mark style=background-color:#f7f7f6>helped </mark><mark style=background-color:#f7f7f6>us </mark><mark style=background-color:#f7f7f7>achieve </mark><mark style=background-color:#f7f7f7>better </mark><mark style=background-color:#f7f7f6>than </mark><mark style=background-color:#f7f7f6>expected </mark><mark style=background-color:#276419>results </mark><mark style=background-color:#f8f2f5>in </mark><mark style=background-color:#f8f5f6>the </mark><mark style=background-color:#f5f7f2>fourth </mark><mark style=background-color:#f1f6ea>quarter </mark><mark style=background-color:#f7f7f6>ended </mark><mark style=background-color:#f7f7f7>february </mark><mark style=background-color:#f7f7f6>28 </mark><mark style=background-color:#edf6e1>its </mark><mark style=background-color:#95cb5c>net </mark><mark style=background-color:#d8efb9>income </mark><mark style=background-color:#f7f7f7>from </mark><mark style=background-color:#f7f7f7>continuing </mark><mark style=background-color:#f7f7f6>operations </mark><mark style=background-color:#f7f7f6>jumped </mark><mark style=background-color:#f7f7f7>52 </mark><mark style=background-color:#f7f7f6>6 </mark><mark style=background-color:#f7f7f6>pct </mark><mark style=background-color:#f7f7f6>to </mark><mark style=background-color:#f7f7f6>20 </mark><mark style=background-color:#f7f7f6>7 </mark><mark style=background-color:#ecf6de>mln </mark><mark style=background-color:#f1f6ea>dlrs </mark><mark style=background-color:#f5f7f2>or </mark><mark style=background-color:#f3f7ef>55 </mark><mark style=background-color:#5a9d29>cts </mark><mark style=background-color:#f5f7f3>a </mark><mark style=background-color:#589b28>share </mark><mark style=background-color:#f8f3f6>in </mark><mark style=background-color:#f7f6f7>the </mark><mark style=background-color:#f7f7f7>latest </mark><mark style=background-color:#f7f7f6>quarter </mark><mark style=background-color:#f7f7f6>as </mark><mark style=background-color:#f7f7f6>sales </mark><mark style=background-color:#f7f7f6>increased </mark><mark style=background-color:#f7f7f6>48 </mark><mark style=background-color:#f7f7f7>3 </mark><mark style=background-color:#f7f7f7>pct </mark><mark style=background-color:#f7f7f7>to </mark><mark style=background-color:#f7f7f6>1 </mark><mark style=background-color:#f7f7f6>58 </mark><mark style=background-color:#f6f7f5>billion </mark><mark style=background-color:#f7f7f6>dlrs </mark><mark style=background-color:#f7f7f7>a </mark><mark style=background-color:#f7f7f7>and </mark><mark style=background-color:#f7f7f7>p </mark><mark style=background-color:#f7f7f6>gave </mark><mark style=background-color:#f7f7f6>no </mark><mark style=background-color:#f7f7f6>details </mark><mark style=background-color:#f7f7f6>on </mark><mark style=background-color:#f7f7f6>the </mark><mark style=background-color:#f7f7f6>expanded </mark><mark style=background-color:#f7f7f6>capital </mark><mark style=background-color:#f7f7f6>program </mark><mark style=background-color:#f7f7f6>but </mark><mark style=background-color:#f7f7f7>it </mark><mark style=background-color:#f7f7f7>did </mark><mark style=background-color:#f7f6f7>say </mark><mark style=background-color:#f8f4f6>it </mark><mark style=background-color:#f7f6f7>completed </mark><mark style=background-color:#f7f7f7>the </mark><mark style=background-color:#f7f7f6>first </mark><mark style=background-color:#f7f7f7>year </mark><mark style=background-color:#f8f4f6>of </mark><mark style=background-color:#f8f5f6>the </mark><mark style=background-color:#f7f7f6>program </mark><mark style=background-color:#f7f7f6>during </mark><mark style=background-color:#f7f7f6>1986 </mark><mark style=background-color:#f7f7f7>a </mark><mark style=background-color:#f7f7f7>and </mark><mark style=background-color:#f7f7f7>p </mark><mark style=background-color:#f7f6f7>is </mark><mark style=background-color:#f7f7f6>52 </mark><mark style=background-color:#f7f7f6>4 </mark><mark style=background-color:#f7f7f6>pct </mark><mark style=background-color:#f8f2f5>owned </mark><mark style=background-color:#f7f6f7>by </mark><mark style=background-color:#f9f1f5>lt </mark><mark style=background-color:#f7f6f7>UNK </mark><mark style=background-color:#f7f7f7>UNK </mark><mark style=background-color:#f7f6f7>of </mark><mark style=background-color:#f7f7f7>west </mark><mark style=background-color:#f7f7f6>germany </mark><mark style=background-color:#f7f7f6>reuter </mark><mark style=background-color:#f7f7f6>3 </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted label =  {}'.format(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted label is not immediately available in the dataset, but you can look a the \n",
    "equivalent value for your prediction label here.\n",
    "\n",
    "\n",
    "\n",
    "|Index | Class name      | Nr of docs train  | Nr of docs test | Mean nr of words in train set |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|  0  |  cocoa           |        55  |  12  | 225.78 |\n",
    "|  1  |  grain           |       432  | 105  | 188.67 |\n",
    "|  2  |  veg-oil         |        74  |  20  | 184.86 |\n",
    "|  3  |  earn            |      3159  | 813  |  87.67 |\n",
    "|  4  |  acq             |      1949  | 474  | 135.83 |\n",
    "|  5  |  wheat           |        17  |   5  | 213.35 |\n",
    "|  6  |  copper          |        48   | 14  | 154.46 |\n",
    "|  7  |  housing         |        16   |  3  | 180.38 |\n",
    "|  8  |  money-supply    |       139  |  38  | 191.48 |\n",
    "|  9  |  coffee          |       101  |  25  | 225.87 |\n",
    "| 10  |  sugar           |       124  |  30  | 184.73 |\n",
    "| 11  |  trade           |       390  |  83  | 253.80 |\n",
    "| 12  |  reserves        |        49  |  13  | 186.92 |\n",
    "| 13  |  ship            |       172  |  37  | 164.66 |\n",
    "| 14  |  cotton          |        26  |   2  | 142.69 |\n",
    "| 15  |  carcass         |        20  |   9  | 170.45 |\n",
    "| 16  |  crude           |       444  |  99  | 219.79 |\n",
    "| 17  |  nat-gas         |        39  |  12  | 149.82 |\n",
    "| 18  |  cpi             |        66  |  20  | 146.85 |\n",
    "| 19  |  money-fx        |       549  | 133  | 185.34 |\n",
    "| 20  |  interest        |       269  |  70  | 201.00 |\n",
    "| 21  |  gnp             |       100  |  27  | 281.83 |\n",
    "| 22  |  meal-feed       |        15  |   7  | 183.73 |\n",
    "| 23  |  alum            |        41  |  12  | 157.34 |\n",
    "| 24  |  oilseed         |        62  |  19  | 151.24 | \n",
    "| 25  |  gold            |        92  |  31  | 152.38 |\n",
    "| 26  |  tin             |        24  |   8  | 259.88 |\n",
    "| 27  |  strategic-metal |       15   |  4   | 145.27 |\n",
    "| 28  |  livestock       |       48   | 10   | 177.48 |\n",
    "| 29  |  retail          |        19  |   4  | 258.32 |\n",
    "|30   | ipi              |       45   | 12   | 175.78 |\n",
    "| 31  |  iron-steel       |       39  |  13  |  157.51 |\n",
    "| 32  |  rubber           |       32  |  10  |  207.44 | \n",
    "| 33  |  heat             |       11  |   5  |  115.55 |\n",
    "| 34  |  jobs             |       50  |   7  |  152.94 |\n",
    "| 35  |  lei              |       10  |   6  |  142.30 | \n",
    "| 36  |  bop              |       49  |  11  |  228.45 |\n",
    "| 37  |  zinc             |       19  |   2  | 164.74 |\n",
    "| 38  |  orange           |       19  |   3  | 130.21 |\n",
    "| 39  |  pet-chem         |       24  |   5  | 153.96 |\n",
    "| 40  |  dlr              |       36  |  10  | 278.39 |\n",
    "| 41  |  gas              |       30  |   8  | 175.07 |\n",
    "| 42  |  silver           |       13  |   3  | 197.92 |\n",
    "| 43  |  wpi              |       21  |   6  | 152.71 |\n",
    "| 44  |  hog              |       12  |   5  |  90.75 |\n",
    "| 45  |  lead             |       18  |   1  | 159.89 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
